{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2431805,"sourceType":"datasetVersion","datasetId":8782}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ver 1.1\n> cutmix 사용안함\n> \n> seed는 고정\n> \n> classifier학습 - 전체학습 2단계 (전체 학습시는 lr을 1e-5로 함. 1e-4는 과적합이 빨리 올수 있다는 충고반영)\n> \n> BatchNorm freeze는 안함\n>\n> acc : 0.9441233140655106, recall : 0.94255940562606\n>\n> confusion_matrix :\n> [[122   0   3   2   0]\n>  [  1  87   3   1   0]\n>  [  0   1  85   1   1]\n>  [  0   0   0 113   5]\n>  [  0   2   1   8  83]]\n>\n> Grad-CAM 적용\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom pathlib import Path\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom albumentations import ToTensorV2\nimport albumentations as A\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.optim import Adam\nfrom torchmetrics.classification import MulticlassF1Score, MulticlassAccuracy,MulticlassRecall","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seed_everything(seed: int = 42):\n    random.seed(seed)          # python random\n    np.random.seed(seed)       # numpy\n    torch.manual_seed(seed)    # torch CPU\n    torch.cuda.manual_seed_all(seed)\n\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(42)\n\nbase_path=Path(r\"/kaggle/input/flowers-recognition/flowers\")\npath_list=[]\n\nfor img_path in base_path.rglob(\"*.jpg\"):\n    path_list.append({\"label\":img_path.parent.name,\"path\":img_path})\n\ndf=pd.DataFrame(path_list)\ndf['targets']=pd.factorize(df['label'])[0]\ndf=df.sample(frac=1,random_state=42).reset_index(drop=True)\n\ntrain_df,tmp_df=train_test_split(df,test_size=0.3,stratify=df['label'],random_state=42)\nval_df,test_df=train_test_split(tmp_df,test_size=0.4,stratify=tmp_df['label'],random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_aug=A.Compose([\n    A.RandomResizedCrop(size=(224,224),scale=(0.8,1.0),ratio=(0.9,1.1),p=1),\n    A.HorizontalFlip(p=0.3),\n    A.Affine(scale=(0.9,1.1),rotate=(-15,15),border_mode=cv2.BORDER_REFLECT_101,p=0.3),\n    A.ColorJitter(brightness=0.2,contrast=0.2,saturation=0.2,hue=0.03,p=0.6),\n    A.CoarseDropout(num_holes_range=(1, 1), hole_height_range=(48, 48),\n                    hole_width_range=(48, 48),fill=0,p=0.25)\n])\n\ntr_resnet34=A.Compose([\n    A.RandomResizedCrop(size=(224,224),scale=(0.8,1.0),ratio=(0.9,1.1),p=1),\n    A.HorizontalFlip(p=0.3),\n    A.Affine(scale=(0.9,1.1),rotate=(-15,15),border_mode=cv2.BORDER_REFLECT_101,p=0.3),\n    A.ColorJitter(brightness=0.2,contrast=0.2,saturation=0.2,hue=0.03,p=0.6),\n    A.CoarseDropout(num_holes_range=(1, 1), hole_height_range=(48, 48),\n                    hole_width_range=(48, 48),fill=0,p=0.25),\n    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\nval_resnet34=A.Compose([\n    A.Resize(224,224,p=1),\n    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize(df,nrows=4,ncols=4,augment=None):\n    df=df.sample(min(nrows*ncols,len(df)))\n    fig,axs=plt.subplots(nrows,ncols,figsize=(ncols*3,nrows*3))\n    axs=axs.flatten()\n    for ax,(_,row) in zip(axs,df.iterrows()):\n        img=cv2.imread(row['path'])\n        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        if augment is not None:\n            img=augment(image=img)['image']\n        H,W=img.shape[:2]\n        label=row['label']\n        ax.imshow(img)\n        ax.set_title(f\"{label}\\n{H}x{W}\")\n    plt.show()\n\nvisualize(df,augment=img_aug)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FlowerCustom(Dataset):\n    def __init__(self,path,targets,augment=None):\n        self.path=path\n        self.targets=targets\n        self.augment=augment\n    def __len__(self):\n        return len(self.path)\n    def __getitem__(self,idx):\n        img=cv2.imread(self.path[idx])\n        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        if self.augment is None:\n            raise ValueError(\"IMG Augment must be need\")\n        img=self.augment(image=img)['image']\n        targets=torch.tensor(self.targets[idx],dtype=torch.long)\n        return img,targets\n\n\ntrain_custom=FlowerCustom(train_df['path'].to_list(),train_df['targets'].to_list(),\n                          augment=tr_resnet34)\nval_custom=FlowerCustom(val_df['path'].to_list(),val_df['targets'].to_list(),\n                        augment=val_resnet34)\ntest_custom=FlowerCustom(test_df['path'].to_list(),test_df['targets'].to_list(),\n                         augment=val_resnet34)\n\ntrain_loader=DataLoader(train_custom,batch_size=32,shuffle=True,num_workers=4,pin_memory=True)\nval_loader=DataLoader(val_custom,batch_size=32,shuffle=False,num_workers=4,pin_memory=True)\ntest_loader=DataLoader(test_custom,batch_size=32,shuffle=False,num_workers=4,pin_memory=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.models import efficientnet_b1,EfficientNet_B1_Weights\n\ndevice=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nweights = EfficientNet_B1_Weights.IMAGENET1K_V2\nmodel=efficientnet_b1(weights=weights).to(device)\nmodel.classifier[1]=nn.Linear(in_features=1280, out_features=5, bias=True).to(device)\n\nfor p in model.parameters():\n    p.requires_grad=False\nfor p in model.classifier.parameters():\n    p.requires_grad=True\noptimizer=Adam(model.classifier.parameters(),lr=1e-3,weight_decay=1e-4)\nscheduler=ReduceLROnPlateau(optimizer,factor=0.1,patience=3)\nloss_func=nn.CrossEntropyLoss()\nmetric_rec=MulticlassRecall(num_classes=5,average=\"macro\").to(device)\nmetric_acc=MulticlassAccuracy(num_classes=5).to(device)\nmetric_f1=MulticlassF1Score(num_classes=5,average='macro').to(device)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from typing import List\nfrom dataclasses import dataclass,field\nfrom tqdm import tqdm\n\n@dataclass\nclass History:\n    training_accuracy:List[float]=field(default_factory=list)\n    training_recall:List[float]=field(default_factory=list)\n    training_loss:List[float]=field(default_factory=list)\n    val_accuracy:List[float]=field(default_factory=list)\n    val_recall:List[float]=field(default_factory=list)\n    val_loss:List[float]=field(default_factory=list)\nhistory=History()\n\n\nclass Trainer:\n    def __init__(self,train_loader,val_loader,model,optimizer,loss_func,\n                 scheduler,metric_acc,metric_rec,device,history,mode=\"min\"):\n        self.model=model\n        self.train_loader=train_loader\n        self.val_loader=val_loader\n        self.optimizer=optimizer\n        self.loss_func=loss_func\n        self.scheduler=scheduler\n        self.metric_acc=metric_acc\n        self.metric_rec=metric_rec\n        self.device=device\n        self.history=history\n        if mode==\"max\":\n            self.best_value=float('-inf')\n        else:\n            self.best_value=float('inf')\n\n    def training_epoch(self,epoch):\n        self.metric_acc.reset()\n        self.metric_rec.reset()\n        self.model.train()\n        loss_sum=0.0\n        avg_loss=0.0\n        with tqdm(total=len(self.train_loader),desc=f\"training {epoch}\",leave=True) as bar:\n            for batch_idx,(x_train,y_train) in enumerate(self.train_loader):\n                x_train=x_train.to(self.device)\n                y_train=y_train.to(self.device)\n                logits=self.model(x_train)\n                loss=self.loss_func(logits,y_train)\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n                loss_sum+=loss.item()\n                avg_loss=loss_sum/(batch_idx+1)\n                preds=logits.argmax(dim=1)   # dim=-1과 같다. (B,12)  1번 dim 즉 행에 대해서\n                self.metric_acc.update(preds, y_train)\n                self.metric_rec.update(preds, y_train)\n                bar.update(1)\n\n                if batch_idx%10==0:\n                    acc=self.metric_acc.compute().item()\n                    recall=self.metric_rec.compute().item()\n                    bar.set_postfix({\"acc\": acc, \"recall\":recall, \"loss\":avg_loss,\"epoch\":epoch})\n            return self.metric_acc.compute().item(), self.metric_rec.compute().item(),avg_loss  \n\n    def validating_epoch(self,epoch):\n        self.metric_acc.reset()\n        self.metric_rec.reset()\n        self.model.eval()\n        loss_sum=0\n        avg_loss=0.0\n        with tqdm(total=len(self.val_loader),desc=f\"validating {epoch}\", leave=True) as bar:\n            with torch.no_grad():\n                for batch_idx,(x_val,y_val) in enumerate(self.val_loader):\n                    x_val=x_val.to(self.device)\n                    y_val=y_val.to(self.device)\n                    logits=self.model(x_val)\n                    loss=self.loss_func(logits,y_val)\n\n                    preds=logits.argmax(dim=-1)\n                    self.metric_acc.update(preds,y_val)\n                    self.metric_rec.update(preds,y_val)\n                    loss_sum+=loss.item()\n                    avg_loss=loss_sum/(batch_idx+1)\n                    bar.update(1)\n                    if batch_idx%10==0:\n                        acc=self.metric_acc.compute().item()\n                        recall=self.metric_rec.compute().item()\n                        bar.set_postfix({\"acc\": acc, \"recall\":recall, \"loss\":avg_loss,\"epoch\":epoch})\n                return self.metric_acc.compute().item(), self.metric_rec.compute().item(),avg_loss\n\n    \n    def fit(self,epochs,early_stop,path):\n        stop_count=0   \n        for epoch in range(epochs):\n            training_accuracy,training_recall,training_loss=self.training_epoch(epoch)\n            self.history.training_accuracy.append(training_accuracy)\n            self.history.training_recall.append(training_recall)\n            self.history.training_loss.append(training_loss)\n            val_accuracy,val_recall,val_loss=self.validating_epoch(epoch)\n            self.history.val_accuracy.append(val_accuracy)\n            self.history.val_recall.append(val_recall)\n            self.history.val_loss.append(val_loss)\n            self.scheduler.step(val_loss)   # scheduler는 early_stop >= scheduler.patience + 1정도가 안정적. ex)scheduler patience = 3이면 early_stop = 5\n            \n            if self.best_value>val_loss:\n                self.best_value=val_loss\n                stop_count=0\n                torch.save(self.model.state_dict(),os.path.join(path,f\"{epoch}_{val_loss}.pt\"))\n            else:\n                stop_count+=1\n                if stop_count>=early_stop:\n                    print(f\"early_stopped. current epoch : {epoch}\")\n                    return self.history\n                    \n        return self.history\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_path=r\"/kaggle/working/\"\n\nt=Trainer(train_loader,val_loader,model,optimizer,loss_func,scheduler,metric_acc,metric_rec,device,history,mode=\"min\")\nhistory=t.fit(5,2,output_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nbest_param=torch.load(r\"/kaggle/working/4_0.31785393834114073.pt\")\nmodel.load_state_dict(best_param)\nfor p in model.parameters():\n    p.requires_grad=True\noptimizer=Adam(model.parameters(),lr=1e-5,weight_decay=1e-4)    # 1e-4는 3,000장에선 다소 공격적\nt1=Trainer(train_loader,val_loader,model,optimizer,loss_func,scheduler,metric_acc,metric_rec,device,history,mode=\"min\")\nhistory=t1.fit(20,5,output_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_param=torch.load(r\"/kaggle/working/19_0.16000709250569345.pt\")\nmodel.load_state_dict(final_param)\n\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nclass GradCAM:\n    def __init__(self, model, target_layer):\n        self.model = model\n        self.target_layer = target_layer\n\n        self.activations = None\n        self.gradients = None\n\n        self.fwd_handle = self.target_layer.register_forward_hook(self._forward_hook)\n        self.bwd_handle = self.target_layer.register_full_backward_hook(self._backward_hook)\n\n    def _forward_hook(self, module, inputs, output):\n        self.activations = output  # (B,C,H,W)\n\n    def _backward_hook(self, module, grad_input, grad_output):\n        self.gradients = grad_output[0]  # (B,C,H,W)\n\n    def remove_hooks(self):\n        self.fwd_handle.remove()\n        self.bwd_handle.remove()\n\n    @torch.enable_grad()\n    def generate(self, x, class_idx=None):\n        \"\"\"\n        x: (B,3,H,W) normalized tensor\n        class_idx: None이면 예측 클래스 기준으로 생성\n        return: cam (B,H,W) in [0,1], pred (B,)\n        \"\"\"\n        self.model.zero_grad(set_to_none=True)\n\n        logits = self.model(x)              # (B,num_classes)\n        pred = logits.argmax(dim=1)         # (B,)\n\n        if class_idx is None:\n            class_idx = pred\n        if isinstance(class_idx, int):\n            class_idx = torch.tensor([class_idx] * x.size(0), device=x.device)\n\n        score = logits[torch.arange(x.size(0)), class_idx].sum()\n        score.backward()\n\n        A = self.activations                # (B,C,h,w)\n        dA = self.gradients                 # (B,C,h,w)\n\n        weights = dA.mean(dim=(2, 3), keepdim=True)      # (B,C,1,1)\n        cam = (weights * A).sum(dim=1, keepdim=True)     # (B,1,h,w)\n        cam = F.relu(cam)\n\n        cam = F.interpolate(cam, size=x.shape[-2:], mode=\"bilinear\", align_corners=False)\n        cam = cam.squeeze(1)  # (B,H,W)\n\n        cam_min = cam.view(cam.size(0), -1).min(dim=1)[0].view(-1, 1, 1)\n        cam_max = cam.view(cam.size(0), -1).max(dim=1)[0].view(-1, 1, 1)\n        cam = (cam - cam_min) / (cam_max - cam_min + 1e-8)\n\n        return cam.detach(), pred.detach()\n\n\nclass Predict:\n    def __init__(self, model, test_loader, device):\n        self.model = model\n        self.test_loader = test_loader\n        self.actual_list = []\n        self.pred_list = []\n        self.device = device\n\n    def predict(self):\n        self.model.eval()\n        with tqdm(total=len(self.test_loader), desc=\"predicting\", leave=True) as bar:\n            for x_test, y_test in self.test_loader:\n                x_test = x_test.to(self.device)\n                y_test = y_test.to(self.device)\n\n                self.actual_list.extend(y_test.detach().cpu().numpy())\n\n                with torch.no_grad():  # 예측만 할 땐 no_grad OK\n                    logits = self.model(x_test)\n                    preds = torch.argmax(logits, dim=-1)\n\n                self.pred_list.extend(preds.detach().cpu().numpy())\n                bar.update(1)\n\n        return self.actual_list, self.pred_list\n\n    # ✅ NameError 방지: 유틸을 클래스 내부로 넣음\n    def _denormalize(self, img_tensor, mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)):\n        img = img_tensor.detach().cpu().float().numpy()     # (3,H,W)\n        img = np.transpose(img, (1, 2, 0))                  # (H,W,3)\n        img = img * np.array(std) + np.array(mean)\n        img = np.clip(img, 0, 1)\n        img = (img * 255).astype(np.uint8)\n        return img\n\n    def _overlay_cam(self, rgb_img_uint8, cam_01, alpha=0.45):\n        heatmap = (cam_01 * 255).astype(np.uint8)\n        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)  # BGR\n        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n        overlay = cv2.addWeighted(rgb_img_uint8, 1 - alpha, heatmap, alpha, 0)\n        return overlay\n\n    def gradcam_visualize(self, num_images=6, target_layer=None, use_true_label=False):\n        \"\"\"\n        num_images: 몇 장 보여줄지\n        target_layer: None이면 EfficientNet-B1에서 model.features[-1] 사용\n        use_true_label: True면 정답 클래스 기준 CAM, False면 예측 클래스 기준 CAM\n        \"\"\"\n        self.model.eval()\n\n        if target_layer is None:\n            # EfficientNet-B1에서 가장 흔한 선택\n            target_layer = self.model.features[-1]\n\n        cam_extractor = GradCAM(self.model, target_layer)\n\n        # test 배치 하나 가져오기\n        x_batch, y_batch = next(iter(self.test_loader))\n        x_batch = x_batch.to(self.device)\n        y_batch = y_batch.to(self.device)\n\n        # ✅ Grad-CAM은 gradient 필요 -> no_grad 금지\n        class_idx = y_batch if use_true_label else None\n        cam, pred = cam_extractor.generate(x_batch, class_idx=class_idx)\n\n        n_show = min(num_images, x_batch.size(0))\n        plt.figure(figsize=(12, 8))\n\n        for i in range(n_show):\n            img = self._denormalize(x_batch[i])          # RGB uint8\n            cam_i = cam[i].cpu().numpy()                 # (H,W)\n            overlay = self._overlay_cam(img, cam_i)\n\n            plt.subplot((n_show + 2)//3, 3, i + 1)\n            plt.imshow(overlay)\n            plt.title(f\"pred={pred[i].item()} / gt={y_batch[i].item()}\")\n            plt.axis(\"off\")\n\n        plt.tight_layout()\n        plt.show()\n\n        cam_extractor.remove_hooks()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"p=Predict(model,test_loader,device)\nactual_list,pred_list=p.predict()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"p.gradcam_visualize(num_images=6)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}